# Neural-Netwrok-with-k-fold-CV
import pandas from keras.models import Sequential from keras.layers import Dense from keras.wrappers.scikit_learn import KerasClassifier from keras.utils import np_utils from sklearn.model_selection import cross_val_score from sklearn.model_selection import KFold from sklearn.preprocessing import LabelEncoder from sklearn.metrics import classification_report, confusion_matrix from sklearn.pipeline import Pipeline # load dataset dataframe = pandas.read_csv("Fused_multi.csv", header=1) dataset = dataframe.values X = dataset[:,0:25].astype(float) Y = dataset[:,25] # encode class values as integers encoder = LabelEncoder() encoder.fit(Y) encoded_Y = encoder.transform(Y) # convert integers to dummy variables (i.e. one hot encoded) dummy_y = np_utils.to_categorical(encoded_Y)   # define baseline model def baseline_model():     # create model   model = Sequential()   model.add(Dense(150,input_dim=25, activation='relu')),   #model.add(Dense(75, activation='relu'))   model.add(Dense(4, activation='softmax'))     # Compile model   model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])   return model   estimator = KerasClassifier(build_fn=baseline_model, epochs=24, batch_size=25, verbose=0) kfold = KFold(n_splits=10, shuffle=True) results = cross_val_score(estimator, X, dummy_y, cv=kfold) print("Baseline: %.2f%% (%.2f%%)" % (results.mean()*100, results.std()*100))
